#!/bin/bash

#############################################################
##
##  B L A C K B A L S A M
##
##  https://github.com/stevencox/blackbalsam
##
##  A multi modal data science environment featuring
##    User Experience: Jupyter Notebooks
##    Visualization: Plotly, Bokeh, Leaflet, Yellowbrick, Seaborn,...
##    Compute: CPU / GPU / Apache Spark
##    Storage: NFS / Minio & S3 / Alluxio
## 
#############################################################
set -ex

DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
BLACKBALSAM_HOME=$( dirname $DIR )

export NAMESPACE=${NAMESPACE:-helx-dev}
export RELEASE=blackbalsam
export JHUB_VERSION=0.8.2
export DIST=$BLACKBALSAM_HOME/bin
export ETC=$BLACKBALSAM_HOME/etc
export NFS_PVC=stdnfs

#############################################################
##
##  Utilities:
##    Make namespace: Initialize the namespace.
##    Set YAML value
##    Generate secrets
##
#############################################################
kc () {
    kubectl --namespace $NAMESPACE $*
}
make_namespace () {
    if [ "$(kubectl get namespaces | grep -c $NAMESPACE)" == 0 ]; then
        kubectl create namespace $NAMESPACE
    fi
}
yaml_set_val () {
    yaml-set \
	--change="$1" \
        --value=$2 \
        -F dquote \
        $3
}
pvc () {
    pvc_name=$NFS_PVC
    pvc_config=$ETC/pvc
    query="{.items[?(@.metadata.name=='"$pvc_name"')].metadata.name}"
    pvc_exists=$(kc get pvc -o=jsonpath="$query" | grep -c $pvc_name || true)
    up () {
	#echo check for persistent volume claim...	
	#pvc_exists=$(kubectl --namespace=$NAMESPACE get pvc | grep -c jhub-nfs-pvc || true)
	if [ "$pvc_exists" -eq 0 ]; then
	    echo install persistent volume claim...
	    kc apply -f $pvc_config
	else
	    echo pvc $pvc_name already exists
	fi
    }    
    status () {
	if [ "$pvc_exists" -eq 0 ]; then
	    echo pvc $pvc_name not found.
	else
	    kc get pvc/$pvc_name -o=yaml
	fi
    }
    down () {
	#pvc_exists=$(kubectl --namespace=$NAMESPACE get pvc | grep -c jhub-nfs-pvc || true)
	if [ "$pvc_exists" -eq 0 ]; then
	    echo pvc $pvc_name does not exist
	else
	    echo deleting pvc $pvc_name...
	    kc delete -f $pvc_config
	fi
    }
    restart () {
	down
	up
    }
    $*
}
secret () {
    secret_name=blackbalsam-secrets
    secret_config=$ETC/secrets/secrets.yaml
    query="{.items[?(@.metadata.name=='"$secret_name"')].metadata.name}"
    secret_exists=$(kc get secrets -o=jsonpath="$query" | grep -c $secret_name || true)
    up () {
	if [ "$secret_exists" -eq 0 ]; then
	    cp $secret_config.template $secret_config
	    yaml_set_val stringData.jupyterhub_secret_token $jupyterhub_secret_token $secret_config
	    yaml_set_val stringData.github_client_secret $github_client_secret $secret_config
            # Minio has standard names for these. Perhaps separate to a different secret.
	    yaml_set_val stringData.accesskey $minio_access_key $secret_config
	    yaml_set_val stringData.secretkey $minio_secret_key $secret_config
	    yaml_set_val stringData.neo4j_password $neo4j_password $secret_config
	    kc apply -f $secret_config
	fi
    }
    name ()  {
        echo $secret_name
    }
    down () {
	if [ "$secret_exists" -eq 0 ]; then
	    echo no secrets found
	else
	    kc delete -f $secret_config
	fi
    }
    status () {
	if [ "$secret_exists" -eq 0 ]; then
	    echo no secrets found
	else
	    kc get secrets/$secret_name -o=yaml
	fi
    }
    restart () {
	down
	up
    }
    $*
}
make_account () {
    kubectl delete --ignore-not-found=true --namespace=$NAMESPACE serviceaccount spark
    kubectl delete --ignore-not-found=true --namespace=$NAMESPACE clusterrolebinding spark-role
    kubectl create --namespace=$NAMESPACE serviceaccount spark
    kubectl create --namespace=$NAMESPACE \
            clusterrolebinding spark-role --clusterrole=edit \
            --serviceaccount=$NAMESPACE:spark
}
#############################################################
##
##  Manage JupyterHub.
##
#############################################################
hub () {
    up () {
	echo installing jupyterhub
        helm version
        cp $ETC/hub/config.yaml.template config.yaml
	yaml_set_val auth.github.clientId $github_client_id config.yaml
	yaml_set_val auth.github.clientSecret $github_client_secret config.yaml
	yaml_set_val auth.github.callbackUrl $github_oauth_callback config.yaml
	yaml_set_val proxy.secretToken $jupyterhub_secret_token config.yaml
	yaml_set_val hub.baseUrl $jupyterhub_baseUrl config.yaml
	
        helm upgrade --install $RELEASE jupyterhub/jupyterhub \
             --namespace $NAMESPACE  \
             --version=$JHUB_VERSION \
             --values config.yaml
        #configure_proxy
        configure_patch
    }
    configure_proxy () {
	if [ "$(kubectl get mapping | grep -c jupyter)" -eq 0 ]; then
            kubectl apply \
                    -f $ETC/ambassador/jupyterhub-ambassador-mapping.yaml \
                    --namespace=$NAMESPACE
	fi
    }
    configure_patch () {
        # https://github.com/jupyterhub/kubespawner/issues/354        
        kubectl patch deploy \
                --namespace $NAMESPACE hub \
                --type json \
                --patch '[{"op": "replace", "path": "/spec/template/spec/containers/0/command", "value": ["bash", "-c", "\nmkdir -p ~/hotfix\ncp -r /usr/local/lib/python3.6/dist-packages/kubespawner ~/hotfix\nls -R ~/hotfix\npatch ~/hotfix/kubespawner/spawner.py << EOT\n72c72\n<             key=lambda x: x.last_timestamp,\n---\n>             key=lambda x: x.last_timestamp and x.last_timestamp.timestamp() or 0.,\nEOT\n\nPYTHONPATH=$HOME/hotfix jupyterhub --config /srv/jupyterhub_config.py --upgrade-db\n"]}]'

    }
    down () {
	echo uninstalling jupyterhub
        helm version
        if [[ "$(helm ls | grep -v NAME | grep -c jupyterhub)" -gt 0 ]]; then
            echo deleting helm release $RELEASE
            helm delete $RELEASE
        fi
    }
    status () {
	query="{.items[?(@.metadata.labels.app=='jupyterhub')].metadata.name}"
	kc describe pods $(kc get pods -o=jsonpath="$query")
    }
    restart () {
        down
        up
    }
    $*
}
helx () {
    if [ ! -d devops ]; then
	git clone https://github.com/helxplatform/devops.git
	cp $ETC/helx/charts/nginx/values.yaml devops/helx/charts/nginx
    fi
    up () {
	cd devops
	helm install helx helx/ -n $NAMESPACE
	cd ..
    }
    down () {
	cd devops
	helm delete helx -n $NAMESPACE
	cd ..
    }
    $*
}
#############################################################
##
##  Manage the software defined reverse proxy.
##
#############################################################
proxy () {
    # Install w/o CRD and change Jupyter to use service annotations, if possible.
    up () {
	echo installing ambassador...
        helm install ambassador --namespace $NAMESPACE --set service.loadBalancerIP=$public_ip datawire/ambassador 
    }
    down () {
	echo uninstalling ambassador...
        if [[ "$(helm ls | grep -v NAME | grep -c ambassador)" == 1 ]]; then
            helm delete ambassador
        fi
        for crd in $(kubectl get customresourcedefinitions | grep ambassador | awk '{ print $1  }'); do
	    echo delelting ambassador customresourcedefinitions...
            kubectl delete customresourcedefinition $crd
        done
    }
    dashboard () {
	wget --timestamping --quiet https://metriton.datawire.io/downloads/darwin/edgectl
	chmod +x edgectl
	query="{.items[?(@.metadata.name=='ambassador')].status.loadBalancer.ingress[0].ip}"
        endpoint_ip=$(kc get svc -o=jsonpath="$query")
        ./edgectl login --namespace=$NAMESPACE $endpoint_ip
    }
    status () {
	query="{.items[?(@.metadata.labels['app\.kubernetes\.io/name']=='ambassador')].metadata.name}"
	kc describe pods $(kc get pods -o=jsonpath="$query")
    }
    restart () {
	down
	up
    }
    $*
}
#############################################################
##
##  Manage the S3 object store.
##
#############################################################
minio () {
    up () {
	echo installing minio...
        if [ "$(helm list | grep -c minio)" == 1 ]; then
            echo == WARNING ==: A minio release is already installed.
        else
            secret_name=$(secret name)
            helm install minio \
                 --set existingSecret=$secret_name \
		 --set persistence.existingClaim=$NFS_PVC \
		 --set persistence.subPath=minio \
                 --namespace $NAMESPACE \
                 stable/minio
        fi
    }
    down () {
	echo uninstalling minio...
        if [[ "$(helm ls | grep -v NAME | awk '{ print $1 }' | grep -c minio)" == 1 ]]; then
            helm delete minio
        fi
    }
    status () {
	query="{.items[?(@.metadata.labels.app=='minio')].metadata.name}"
	kc describe pods $(kc get pods -o=jsonpath="$query")
    }
    restart () {
	down
	up
    }
    $*
}
#############################################################
##
##  Manage the memory cache data fabric.
##
#############################################################
alluxio () {
    up () {
	echo installing alluxio...
        echo "Configuring and starting alluxio..."
        export ALLUXIO_MASTER_HOST=alluxio-master-0
        export ALLUXIO_WORKER_HOST=alluxio-worker
        export MINIO_BUCKET=covid-19
        export MINIO_HOST=minio
        export MINIO_PORT=9000
        export MINIO_ACCESS_KEY=$minio_access_key
        export MINIO_SECRET_KEY=$minio_secret_key
        export alluxio_conf="./tmp/alluxio-k8s/singleMaster-localJournal/alluxio-configmap.yaml"
	export alluxio_statefulset_conf="./tmp/alluxio-k8s/singleMaster-localJournal/master/alluxio-master-statefulset.yaml"
        export alluxio_daemonset_conf="./tmp/alluxio-k8s/singleMaster-localJournal/worker/alluxio-worker-daemonset.yaml"
	
	echo copying alluxio config templates...
	mkdir -p tmp
	cp -r alluxio-k8s ./tmp
	envsubst < ${alluxio_conf}.template > $alluxio_conf
	envsubst < ${alluxio_statefulset_conf}.template > $alluxio_statefulset_conf
	envsubst < ${alluxio_daemonset_conf}.template > $alluxio_daemonset_conf
	find ./tmp -name "*.template" -print | xargs rm
	x () {
	cat $alluxio_conf
	cat $alluxio_statefulset_conf
	cat $alluxio_daemonset_conf 
	exit 0
	}
        echo "  configured. creating kubernetes artifacts."
        kubectl apply \
		--namespace $NAMESPACE \
		--recursive=true \
		-f ./tmp/alluxio-k8s
	rm -rf ./tmp/alluxio-k8s	
    }
    down () {
        echo "uninstalling alluxio..."
        kubectl delete \
		--ignore-not-found=true \
		--namespace $NAMESPACE \
		--recursive=true \
		-f alluxio-k8s
    }
    status () {
	query="{.items[?(@.metadata.labels.app=='alluxio')].metadata.name}"
	kc describe pods $(kc get pods -o=jsonpath="$query")
    }
    restart () {
        down
        up
    }
    $*
}
#############################################################
##
## Manage the Neo4J database.
##
#############################################################
neo4j () {
    up () {
	kubectl --namespace $NAMESPACE apply -f etc/neo4j
    }
    down () {
	kubectl --namespace $NAMESPACE --ignore-not-found=true delete -f etc/neo4j
    }
    status () {
	query="{.items[?(@.metadata.labels.app=='neo4j')].metadata.name}"
	kc describe pods $(kc get pods -o=jsonpath="$query")
    }
    restart () {
	down
	up
    }
    $*
}
#############################################################
##
## Manage the data corpus this cluster provides
##
#############################################################
data () {
    up () {
	# Create the updater.
	kc apply -f etc/data/updater
    }
    down () {
	# Delete the udpater.
	kc delete -f etc/data/updater
    }
    run () {
	# Run a refresh job now.
	kc create job --from=cronjob/update-data-set update-data
    }
    stop () {
	# Stop the running refresh job.
	kc delete job/update-data
    }
    status () {
	# Get status
	query="{.items[?(@.metadata.name=='update-data-set')].metadata.name}"
	kc describe cronjobs $(kc get pods -o=jsonpath="$query")
    }
    restart () {
	# Restart the data service
	stop
	down
	up
    }
    $*
}
#############################################################
##
##  Manage the system as a whole.
##
#############################################################
SYSTEMS="secret pvc minio alluxio proxy neo4j hub"
SYSTEMS="secret pvc minio alluxio helx neo4j hub"
up () {
    echo installing blackbalsam...
    for system in $SYSTEMS; do
	echo "  --installing $system"
        $system up
    done
}
down () {
    echo uninstalling blackbalsam...
    reversed="$(echo $SYSTEMS | awk '{ for (i=NF; i>1; i--) printf("%s ",$i); print $1; }')"
    for system in $reversed; do
        $system down
    done
    #kubectl delete --ignore-not-found=true namespace $NAMESPACE
}
restart () {
    echo "restarting blackbalsam"
    echo "   bringing the system down..."
    down
    echo "   bringing the system up..."
    up
}
status () {
    for kind in deployment pod service pvc pv; do
        message=$( echo $kind | awk '{ print toupper($0) }' )
        echo $message
        kubectl get -n $NAMESPACE $kind 2>&1 | sed "s,^,   ,g"
    done
}
nodes () {
    kubectl describe nodes
}
#############################################################
##
##  Initialize.
##
#############################################################
init () {
    # Require an init file.
    if [ ! -f $HOME/.blackbalsam ]; then
        echo $HOME/.blackbalsam must exist and contain a variable called jupyterhub_secret_token
        exit 1
    fi
    source $HOME/.blackbalsam
}
configure () {
    helm version
    helm repo add stable https://kubernetes-charts.storage.googleapis.com
    helm repo add datawire https://www.getambassador.io
    helm repo add jupyterhub https://jupyterhub.github.io/helm-chart/
    helm repo update
}

#############################################################
##
##  Help.
##
#############################################################
help () { 
    printf "\
$0 is the command line interface for a Blackbalsam data science cluster.

Each of these commands include up, down, status, and restart.

  eg: bin/blackbalsam <command> [ up | down | status | restart ]

User Experience Services:
  hub   \tManage the JupyterHub and associated proxy mappings, storage, etc.

Storage Services:
  alluxio \tManage Alluxio services and distributed workers.
  minio \tManage Minio S3 interface. Creates a service called 'minio'.

Proxy Services:
  proxy \tManage the programmable Ambassador edge proxy.

Data Services:
  data   \tInstall the periodic data update task for this cluster.
  data run\tRun the periodic data update task now.
  data stop\tStop the running data update task if one exists

Secrets:
  secret  \tManage secrets based on environment conifguration.

General:
  up    \tExecute configurations and start all services.
  down  \tStop all cluster services.
  restart\tStop and start all system components.
  status\tReport on Kubernetes components and system services in detail.
  nodes \tDisplay detailed usage and status for cluster nodes.
  help  \tShow this message.
"
}

init

$*

exit 0
